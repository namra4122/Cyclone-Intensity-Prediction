{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b608a42",
   "metadata": {},
   "source": [
    "# Alexnet Model Building & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e347ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that trains and validates the model and returns the MSE\n",
    "def train_val_model(train_x,train_y,val_x,val_y, n_epochs, batch_size):\n",
    "    reg_param = 1e-5\n",
    "    \n",
    "    train_X = tf.convert_to_tensor(train_x)\n",
    "    train_Y = tf.convert_to_tensor(train_y)\n",
    "    train_X = tf.image.per_image_standardization(train_X)\n",
    "    \n",
    "    val_X = tf.convert_to_tensor(val_x)\n",
    "    val_Y = tf.convert_to_tensor(val_y)\n",
    "    val_X = tf.image.per_image_standardization(val_X)\n",
    "    \n",
    "    weights_initializer = keras.initializers.GlorotUniform()\n",
    "    \n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        Preprocessing(),\n",
    "        keras.layers.Conv2D(filters=16, kernel_size=4, strides=2, padding='valid', activation='relu', kernel_initializer = weights_initializer, kernel_regularizer=keras.regularizers.l2(reg_param)),\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='valid', activation='relu', kernel_initializer = weights_initializer, kernel_regularizer=keras.regularizers.l2(reg_param)),\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='valid', activation='relu', kernel_initializer = weights_initializer, kernel_regularizer=keras.regularizers.l2(reg_param)),\n",
    "        keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='valid', activation='relu', kernel_initializer = weights_initializer, kernel_regularizer=keras.regularizers.l2(reg_param)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(256, activation='relu', kernel_initializer = weights_initializer, kernel_regularizer=keras.regularizers.l2(reg_param)),\n",
    "        keras.layers.Dense(128, activation='relu', kernel_initializer = weights_initializer, kernel_regularizer=keras.regularizers.l2(reg_param)),\n",
    "        keras.layers.Dense(1, activation='relu', kernel_initializer = weights_initializer, kernel_regularizer=keras.regularizers.l2(reg_param)),\n",
    "    ])\n",
    "    \n",
    "    #Compiling the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error', #Computes the mean of squares of errors between labels and predictions\n",
    "                  metrics=[['mean_squared_error']], #Computes the mean squared error between y_true and y_pred\n",
    "                 )\n",
    "    \n",
    "    #Training the network\n",
    "    history = model.fit(train_X,train_Y, \n",
    "         epochs=n_epochs,\n",
    "         batch_size=batch_size, \n",
    "         verbose=1,\n",
    "         validation_split=0.1,\n",
    "        )\n",
    "    \n",
    "    val_score = model.evaluate(val_X, val_Y)\n",
    "    print(\"Val Score: \",val_score)\n",
    "\n",
    "    return history,val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273289b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\cyclone_env\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 10s 208ms/step - loss: 1043.0728 - mean_squared_error: 1043.0665 - val_loss: 368.2254 - val_mean_squared_error: 368.2200\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 8s 177ms/step - loss: 519.7153 - mean_squared_error: 519.7105 - val_loss: 286.0712 - val_mean_squared_error: 286.0665\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 8s 176ms/step - loss: 411.9991 - mean_squared_error: 411.9945 - val_loss: 260.0824 - val_mean_squared_error: 260.0779\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 379.5771 - mean_squared_error: 379.5726 - val_loss: 229.5377 - val_mean_squared_error: 229.5332\n",
      "Epoch 5/15\n",
      "43/43 [==============================] - 6s 146ms/step - loss: 370.4024 - mean_squared_error: 370.3979 - val_loss: 212.7671 - val_mean_squared_error: 212.7626\n",
      "Epoch 6/15\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 368.1569 - mean_squared_error: 368.1523 - val_loss: 275.3617 - val_mean_squared_error: 275.3572\n",
      "Epoch 7/15\n",
      "43/43 [==============================] - 8s 176ms/step - loss: 349.0091 - mean_squared_error: 349.0046 - val_loss: 274.6812 - val_mean_squared_error: 274.6767\n",
      "Epoch 8/15\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 346.9207 - mean_squared_error: 346.9162 - val_loss: 230.2492 - val_mean_squared_error: 230.2446\n",
      "Epoch 9/15\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 339.4077 - mean_squared_error: 339.4031 - val_loss: 300.3721 - val_mean_squared_error: 300.3675\n",
      "Epoch 10/15\n",
      "43/43 [==============================] - 6s 148ms/step - loss: 323.2117 - mean_squared_error: 323.2071 - val_loss: 240.7990 - val_mean_squared_error: 240.7943\n",
      "Epoch 11/15\n",
      "43/43 [==============================] - 7s 154ms/step - loss: 334.2258 - mean_squared_error: 334.2211 - val_loss: 198.7838 - val_mean_squared_error: 198.7791\n",
      "Epoch 12/15\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 304.6963 - mean_squared_error: 304.6916 - val_loss: 261.5351 - val_mean_squared_error: 261.5305\n",
      "Epoch 13/15\n",
      "43/43 [==============================] - 7s 154ms/step - loss: 309.9628 - mean_squared_error: 309.9582 - val_loss: 241.3871 - val_mean_squared_error: 241.3824\n",
      "Epoch 14/15\n",
      "43/43 [==============================] - 7s 158ms/step - loss: 309.9536 - mean_squared_error: 309.9489 - val_loss: 191.4425 - val_mean_squared_error: 191.4379\n",
      "Epoch 15/15\n",
      "43/43 [==============================] - 6s 149ms/step - loss: 331.0907 - mean_squared_error: 331.0860 - val_loss: 298.2431 - val_mean_squared_error: 298.2384\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 580.2202 - mean_squared_error: 580.2153\n",
      "Val Score:  [580.2201538085938, 580.21533203125]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 10s 149ms/step - loss: 1012.1340 - mean_squared_error: 1012.1275 - val_loss: 550.3263 - val_mean_squared_error: 550.3210\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 9s 141ms/step - loss: 511.2996 - mean_squared_error: 511.2944 - val_loss: 477.5038 - val_mean_squared_error: 477.4987\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 9s 132ms/step - loss: 453.1766 - mean_squared_error: 453.1716 - val_loss: 534.1393 - val_mean_squared_error: 534.1342\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 7s 107ms/step - loss: 438.7033 - mean_squared_error: 438.6982 - val_loss: 482.2858 - val_mean_squared_error: 482.2805\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 10s 149ms/step - loss: 416.9400 - mean_squared_error: 416.9348 - val_loss: 552.7776 - val_mean_squared_error: 552.7723\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 9s 132ms/step - loss: 385.9934 - mean_squared_error: 385.9881 - val_loss: 662.0045 - val_mean_squared_error: 661.9990\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 8s 131ms/step - loss: 383.8381 - mean_squared_error: 383.8326 - val_loss: 458.5339 - val_mean_squared_error: 458.5285\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 11s 171ms/step - loss: 383.7288 - mean_squared_error: 383.7233 - val_loss: 470.8933 - val_mean_squared_error: 470.8879\n",
      "Epoch 9/15\n",
      "65/65 [==============================] - 10s 152ms/step - loss: 362.0696 - mean_squared_error: 362.0641 - val_loss: 462.7899 - val_mean_squared_error: 462.7844\n",
      "Epoch 10/15\n",
      "65/65 [==============================] - 10s 149ms/step - loss: 366.9661 - mean_squared_error: 366.9604 - val_loss: 461.3357 - val_mean_squared_error: 461.3300\n",
      "Epoch 11/15\n",
      "65/65 [==============================] - 8s 115ms/step - loss: 353.6535 - mean_squared_error: 353.6479 - val_loss: 430.0587 - val_mean_squared_error: 430.0529\n",
      "Epoch 12/15\n",
      "65/65 [==============================] - 11s 166ms/step - loss: 358.3884 - mean_squared_error: 358.3826 - val_loss: 616.8671 - val_mean_squared_error: 616.8612\n",
      "Epoch 13/15\n",
      "65/65 [==============================] - 9s 138ms/step - loss: 375.4080 - mean_squared_error: 375.4021 - val_loss: 521.9721 - val_mean_squared_error: 521.9660\n",
      "Epoch 14/15\n",
      "65/65 [==============================] - 10s 152ms/step - loss: 314.4616 - mean_squared_error: 314.4555 - val_loss: 414.8444 - val_mean_squared_error: 414.8381\n",
      "Epoch 15/15\n",
      "65/65 [==============================] - 10s 156ms/step - loss: 297.2462 - mean_squared_error: 297.2400 - val_loss: 424.2745 - val_mean_squared_error: 424.2681\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 301.9938 - mean_squared_error: 301.9873\n",
      "Val Score:  [301.9937744140625, 301.9873352050781]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 8s 154ms/step - loss: 1164.9167 - mean_squared_error: 1164.9100 - val_loss: 730.1013 - val_mean_squared_error: 730.0952\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 7s 171ms/step - loss: 668.3780 - mean_squared_error: 668.3723 - val_loss: 430.8853 - val_mean_squared_error: 430.8798\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 9s 199ms/step - loss: 485.5703 - mean_squared_error: 485.5649 - val_loss: 366.0823 - val_mean_squared_error: 366.0769\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 8s 177ms/step - loss: 466.8949 - mean_squared_error: 466.8895 - val_loss: 364.1635 - val_mean_squared_error: 364.1581\n",
      "Epoch 5/15\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 451.5438 - mean_squared_error: 451.5385 - val_loss: 334.1339 - val_mean_squared_error: 334.1285\n",
      "Epoch 6/15\n",
      "43/43 [==============================] - 6s 136ms/step - loss: 460.1080 - mean_squared_error: 460.1027 - val_loss: 336.0149 - val_mean_squared_error: 336.0095\n",
      "Epoch 7/15\n",
      "43/43 [==============================] - 7s 152ms/step - loss: 440.8087 - mean_squared_error: 440.8033 - val_loss: 315.2824 - val_mean_squared_error: 315.2770\n",
      "Epoch 8/15\n",
      "43/43 [==============================] - 7s 156ms/step - loss: 427.8098 - mean_squared_error: 427.8043 - val_loss: 303.4435 - val_mean_squared_error: 303.4380\n",
      "Epoch 9/15\n",
      "43/43 [==============================] - 6s 132ms/step - loss: 449.0511 - mean_squared_error: 449.0457 - val_loss: 391.4844 - val_mean_squared_error: 391.4789\n",
      "Epoch 10/15\n",
      "43/43 [==============================] - 6s 150ms/step - loss: 407.8243 - mean_squared_error: 407.8188 - val_loss: 294.0561 - val_mean_squared_error: 294.0506\n",
      "Epoch 11/15\n",
      "43/43 [==============================] - 7s 155ms/step - loss: 391.9748 - mean_squared_error: 391.9692 - val_loss: 284.1373 - val_mean_squared_error: 284.1317\n",
      "Epoch 12/15\n",
      "43/43 [==============================] - 8s 178ms/step - loss: 386.6673 - mean_squared_error: 386.6616 - val_loss: 284.4812 - val_mean_squared_error: 284.4756\n",
      "Epoch 13/15\n",
      "43/43 [==============================] - 7s 164ms/step - loss: 384.2319 - mean_squared_error: 384.2261 - val_loss: 284.1342 - val_mean_squared_error: 284.1284\n",
      "Epoch 14/15\n",
      "43/43 [==============================] - 8s 178ms/step - loss: 376.1812 - mean_squared_error: 376.1755 - val_loss: 276.5075 - val_mean_squared_error: 276.5017\n",
      "Epoch 15/15\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 368.7931 - mean_squared_error: 368.7873 - val_loss: 284.8661 - val_mean_squared_error: 284.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 6ms/step - loss: 429.4402 - mean_squared_error: 429.4343\n",
      "Val Score:  [429.4402160644531, 429.4342956542969]\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs=15\n",
    "batch_size=64\n",
    "model_history = []  #save the model history in a list after fitting so that we can plot later\n",
    "val_scores=[]\n",
    "kf = model_selection.KFold(n_splits=3)\n",
    "\n",
    "i=0\n",
    "for train_index, test_index in kf.split(X_irpmw):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    i+=1\n",
    "    tr = len(train_index)\n",
    "    te = len(test_index)\n",
    "    train_x = X_irpmw[train_index[0]:train_index[tr-1]]\n",
    "    val_x = X_irpmw[test_index[0]:test_index[te-1]]\n",
    "    train_y= y[train_index[0]:train_index[tr-1]]\n",
    "    val_y = y[test_index[0]:test_index[te-1]]\n",
    "    history,val_score = train_val_model(train_x,train_y,val_x,val_y, n_epochs, batch_size)\n",
    "    model_history.append(history)\n",
    "    val_scores.append(val_score)\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29226978",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "plt.title('Train Accuracy vs Val Accuracy, batch size is 64')\n",
    "colors=['black','red','green','purple','orange']\n",
    "for i in range(3):\n",
    "    plt.plot(model_history[i].history['mean_squared_error'], label='Train MSE Fold '+str(i+1), color=colors[i])\n",
    "    plt.plot(model_history[i].history['val_mean_squared_error'], label='Val MSE Fold '+str(i+1), color=colors[i], linestyle = \"dashdot\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylim(0,1000)\n",
    "plt.text(20,800,\"MSE on validation sets: \"+str([int(v) for v,v2 in val_scores]))\n",
    "plt.text(20,700,\"mean MSE on validation set: \"+str(int(np.mean(val_scores,axis=0)[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed49b29",
   "metadata": {},
   "source": [
    "# deep-PHURIE Model Building and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df60681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 220, 220, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 108, 108, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 108, 108, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 106, 106, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 52, 52, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 52, 52, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 50, 50, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 48, 48, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 48, 48, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 46, 46, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 44, 44, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 44, 44, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 42, 42, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 40, 40, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 40, 40, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 38, 38, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 36, 36, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 41472)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               10617088  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,701,089\n",
      "Trainable params: 10,699,937\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Create a sequential deepPHURIE_model\n",
    "deepPHURIE_model = Sequential()\n",
    "\n",
    "# First Convolutional layer\n",
    "deepPHURIE_model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(224, 224, 3), activation='relu'))\n",
    "deepPHURIE_model.add(MaxPooling2D(pool_size=(5, 5), strides=(2, 2)))\n",
    "deepPHURIE_model.add(BatchNormalization())\n",
    "\n",
    "# 2 Convolutional layers\n",
    "deepPHURIE_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "deepPHURIE_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "deepPHURIE_model.add(BatchNormalization())\n",
    "\n",
    "# 3 Convolutional layers\n",
    "deepPHURIE_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "deepPHURIE_model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "deepPHURIE_model.add(BatchNormalization())\n",
    "\n",
    "# 4 Convolutional layers\n",
    "deepPHURIE_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "deepPHURIE_model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "deepPHURIE_model.add(BatchNormalization())\n",
    "\n",
    "# 5 Convolutional layers\n",
    "deepPHURIE_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "deepPHURIE_model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "deepPHURIE_model.add(BatchNormalization())\n",
    "\n",
    "# 6 Convolutional layers\n",
    "deepPHURIE_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "deepPHURIE_model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "deepPHURIE_model.add(BatchNormalization())\n",
    "\n",
    "# Flatten the output to feed into fully connected layers\n",
    "deepPHURIE_model.add(Flatten())\n",
    "\n",
    "# First fully connected layer\n",
    "deepPHURIE_model.add(Dense(256, activation='relu'))\n",
    "deepPHURIE_model.add(Dropout(0.5))  # Dropout for regularization\n",
    "deepPHURIE_model.add(BatchNormalization())\n",
    "\n",
    "# Second fully connected layer\n",
    "deepPHURIE_model.add(Dense(128, activation='relu'))\n",
    "deepPHURIE_model.add(Dropout(0.5))  # Dropout for regularization\n",
    "deepPHURIE_model.add(BatchNormalization())\n",
    "\n",
    "# Output layer\n",
    "deepPHURIE_model.add(Dense(1, activation='linear'))  # Assuming the output is a single value for intensity prediction\n",
    "\n",
    "# Compile the deepPHURIE_model\n",
    "deepPHURIE_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Display the deepPHURIE_model summary\n",
    "deepPHURIE_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that trains and validates the model and returns the MSE\n",
    "def deepPHURIE_model_train_val_model(train_x,train_y,val_x,val_y, n_epochs, batch_size,model):\n",
    "    reg_param = 1e-5\n",
    "    \n",
    "    train_X = tf.convert_to_tensor(train_x)\n",
    "    train_Y = tf.convert_to_tensor(train_y)\n",
    "    train_X = tf.image.per_image_standardization(train_X)\n",
    "    \n",
    "    val_X = tf.convert_to_tensor(val_x)\n",
    "    val_Y = tf.convert_to_tensor(val_y)\n",
    "    val_X = tf.image.per_image_standardization(val_X)\n",
    "    \n",
    "    # weights_initializer = keras.initializers.GlorotUniform()\n",
    "    \n",
    "    #Compiling the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error', #Computes the mean of squares of errors between labels and predictions\n",
    "                  metrics=[['mean_squared_error']], #Computes the mean squared error between y_true and y_pred\n",
    "                 )\n",
    "    \n",
    "    #Training the network\n",
    "    history = model.fit(train_X,train_Y, \n",
    "         epochs=n_epochs,\n",
    "         batch_size=batch_size, \n",
    "         verbose=1,\n",
    "         validation_split=0.1,\n",
    "        )\n",
    "    \n",
    "    val_score = model.evaluate(val_X, val_Y)\n",
    "    print(\"Val Score: \",val_score)\n",
    "\n",
    "    return history,val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a809de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=15\n",
    "batch_size=64\n",
    "model_history = []  #save the model history in a list after fitting so that we can plot later\n",
    "val_scores=[]\n",
    "kf = model_selection.KFold(n_splits=3)\n",
    "\n",
    "i=0\n",
    "for train_index, test_index in kf.split(X_irpmw):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    i+=1\n",
    "    tr = len(train_index)\n",
    "    te = len(test_index)\n",
    "    train_x = X_irpmw[train_index[0]:train_index[tr-1]]\n",
    "    val_x = X_irpmw[test_index[0]:test_index[te-1]]\n",
    "    train_y= y[train_index[0]:train_index[tr-1]]\n",
    "    val_y = y[test_index[0]:test_index[te-1]]\n",
    "    history,val_score = deepPHURIE_model_train_val_model(train_x,train_y,val_x,val_y, n_epochs, batch_size, deepPHURIE_model)\n",
    "    model_history.append(history)\n",
    "    val_scores.append(val_score)\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
